<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>RD-VIO: Robust Visual-Inertial Odometry for Mobile Augmented Reality in Dynamic Environments</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      font-family: 'Segoe UI', Arial, sans-serif;
      background: #ffffff;
      color: #333333;
      margin: 0;
      padding: 0;
      line-height: 1.6;
    }
    .container {
      max-width: 1000px;
      margin: 0 auto;
      padding: 40px 20px;
    }
    .header {
      text-align: center;
      margin-bottom: -50px;
      padding: 40px 0;
      border-radius: 10px;
    }
    .header h1 {
      font-size: 3em;
      margin: 0 0 15px 0;
      font-weight: 300;
    }
    .header .subtitle {
      font-size: 1.3em;
      opacity: 0.9;
    }
    .nav-links {
      display: flex;
      justify-content: center;
      gap: 20px;
      margin: 30px 0;
      flex-wrap: wrap;
    }
    .nav-links a {
      color: #222;
      text-decoration: none;
      padding: 8px 24px;
      border: 1px solid #bbb;
      border-radius: 15px;
      transition: all 0.3s ease;
      background: #fff;
    }
    .nav-links a:hover {
      background: #f0f0f0;
      border-color: #222;
      color: #000;
    }
    .nav-links img {
      filter: none !important;
    }
    .section {
      margin-bottom: 50px;
    }
    .section h2 {
      font-size: 2em;
      margin-bottom: 20px;
      color: #000000;
      border-bottom: 3px solid #667eea;
      padding-bottom: 10px;
    }
    .abstract {
      background: #f8f9fa;
      padding: 30px;
      border-radius: 10px;
      font-size: 1.1em;
      border-left: 5px solid #667eea;
      border: 1px solid #e9ecef;
    }
    .video-container {
      text-align: center;
      margin: 30px 0;
    }
    .video-placeholder {
      width: 100%;
      height: 400px;
      background: #f8f9fa;
      border: 2px dashed #dee2e6;
      display: flex;
      align-items: center;
      justify-content: center;
      border-radius: 10px;
      font-size: 1.2em;
      color: #6c757d;
    }
    .authors {
      text-align: center;
      margin: 10px 0 30px 0;
      font-size: 1.1em;
    }
    .authors a {
      color: #667eea;
      text-decoration: none;
      margin: 0 5px;
    }
    .authors a:hover {
      color: #5a6fd8;
    }
    .bibtex {
      background: #f8f9fa;
      padding: 20px;
      border-radius: 8px;
      font-family: 'Courier New', monospace;
      font-size: 0.9em;
      overflow-x: auto;
      border: 1px solid #dee2e6;
      color: #495057;
    }
    .download-section {
      background: #f8f9fa;
      padding: 30px;
      border-radius: 10px;
      text-align: center;
      border: 1px solid #dee2e6;
    }
    .download-links {
      display: flex;
      justify-content: center;
      gap: 20px;
      margin: 20px 0;
      flex-wrap: wrap;
    }
    .download-links a {
      display: inline-block;
      padding: 15px 30px;
      background: #667eea;
      color: white;
      text-decoration: none;
      border-radius: 8px;
      transition: background 0.3s ease;
      font-weight: bold;
      border: 1px solid #5a6fd8;
    }
    .download-links a:hover {
      background: #5a6fd8;
      border-color: #4c63d2;
    }
    .results-grid {
      display: grid;
      grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
      gap: 20px;
      margin: 30px 0;
    }
    .result-item {
      background: #f8f9fa;
      padding: 20px;
      border-radius: 8px;
      text-align: center;
      border: 1px solid #dee2e6;
    }
    .result-item h3 {
      color: #000000;
      margin-top: 0;
    }
    ul {
      color: #333333;
    }
    ul li strong {
      color: #667eea;
    }
    a {
      color: #667eea;
    }
    a:hover {
      color: #5a6fd8;
    }
    @media (max-width: 768px) {
      .header h1 {
        font-size: 2.2em;
      }
      .nav-links {
        flex-direction: column;
        align-items: center;
      }
      .download-links {
        flex-direction: column;
        align-items: center;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
    <h2>
      RD-VIO:
      <span style="color:#e93819;">R</span>obust
      <span style="color:#e93819;">V</span>isual-<span style="color:#e93819;">I</span>nertial 
      <span style="color:#e93819;">O</span>dometry for Mobile Augmented Reality in <br>
      <span style="color:#e93819;">D</span>ynamic Environments 
    </h2>
    
    <div style="text-align:center; margin-bottom:18px; font-size:1.05em; color:#495057;"></div>
      <strong>Note:</strong> 
        RD-VIO is an important module of 
        <a href="https://github.com/openxrlab" target="_blank" style="color:#667eea;text-decoration:underline;">OpenXRLab</a>. 
        For more details, please refer to <a href="https://github.com/openxrlab/xrslam" target="_blank" style="color:#667eea;text-decoration:underline;">xrslam</a>.
    </div>

    <div class="nav-links">
      <a href="https://arxiv.org/pdf/2310.15072">
        <img src="source/logo/adobeacrobatreader.svg" alt="PDF" style="height:1em;vertical-align:middle;margin-right:6px;filter:invert(1);">PDF
      </a>
      <a href="https://arxiv.org/abs/2310.15072">
        <img src="source/logo/arxiv.svg" alt="arXiv" style="height:1em;vertical-align:middle;margin-right:6px;filter:invert(1);">arXiv
      </a>
      <a href="https://github.com/openxrlab/xrslam">
        <img src="source/logo/github.svg" alt="GitHub" style="height:1em;vertical-align:middle;margin-right:6px;filter:invert(1);">Code
      </a>
    </div>

    <div class="authors">
      <a href="#">Jinyu Li<sup>1*</sup></a>,
      <a href="#">Xiaokun Pan<sup>1*</sup></a>,
      <a href="#">Gan Huang<sup>1</sup></a>,
      <a href="#">Ziyang Zhang<sup>1</sup></a>,
      <a href="#">Nan Wang<sup>2</sup></a>,
      <a href="#">Hujun Bao<sup>1</sup></a>,
      <a href="http://www.cad.zju.edu.cn/home/gfzhang/">Guofeng Zhang<sup>1<sup>†</sup></sup></a><br>
    <br>
    <em><sup>1</sup> State Key Lab of CAD&amp;CG, Zhejiang University</em>&nbsp;&nbsp;&nbsp;
    <em><sup>2</sup> SenseTime Research</em>
    <br>
    <em><sup>*</sup> Equal Contribution</em> &nbsp;&nbsp;&nbsp;
    <em><sup>†</sup> Corresponding author</em> 
    </div>


    <img src="source/teaser.png" alt="RD-VIO Overview" style="width:100%; border-radius:10px; box-shadow: 0 2px 8px rgba(0,0,0,0.1);">
    <p style="text-align:center; color:#6c757d;">Figure 1: Overview of RD-VIO system.</p>


    <div class="section">
      <h2>Abstract</h2>
      <div class="abstract">
        It is typically challenging for visual or visual-inertial odometry systems to handle the problems of dynamic scenes and pure rotation. In this work, we design a novel visual-inertial odometry (VIO) system called RD-VIO to handle both of these two problems. Firstly, we propose an IMU-PARSAC algorithm which can robustly detect and match keypoints in a two-stage process. In the first state, landmarks are matched with new keypoints using visual and IMU measurements. We collect statistical information from the matching and then guide the intra-keypoint matching in the second stage. Secondly, to handle the problem of pure rotation, we detect the motion type and adapt the deferred-triangulation technique during the data-association process. We make the pure-rotational frames into the special subframes. When solving the visual-inertial bundle adjustment, they provide additional constraints to the pure-rotational motion. We evaluate the proposed VIO system on public datasets and online comparison. Experiments show the proposed RD-VIO has obvious advantages over other methods in dynamic environments.
      </div>
    </div>

    <div class="section" id="video">
      <h2>Video</h2>
      <div class="video-container">
        <div class="video-placeholder">
          Video Placeholder<br>
          (Replace with actual video embed)
        </div>
      </div>
    </div>

    <div class="section">
      <h2>Key Features</h2>
      <ul style="font-size: 1.1em; line-height: 1.8;">
        <li><strong>Robust to challenging motion:</strong> Handle pure rotational motion that often cause failures in other VIO systems.</li>
        <li><strong>Dynamic outlier removal:</strong> Effectively detect and remove dynamic outliers in the scene.</li>
        <li><strong>Open-source implementation:</strong> The full system is released, including the core VIO algorithm and an iOS project for mobile AR applications.</li>
      </ul>
    </div>

    <!-- <div class="section">
      <h2>Experimental Results</h2>
      <div class="results-grid">
        <div class="result-item">
          <h3>EuRoC Dataset</h3>
          <p>Average RMSE: <strong>0.12m</strong></p>
          <p>Success Rate: <strong>95%</strong></p>
        </div>
        <div class="result-item">
          <h3>TUM-VI Dataset</h3>
          <p>Average RMSE: <strong>0.15m</strong></p>
          <p>Success Rate: <strong>92%</strong></p>
        </div>
        <div class="result-item">
          <h3>Real Robot Tests</h3>
          <p>Average RMSE: <strong>0.18m</strong></p>
          <p>Success Rate: <strong>88%</strong></p>
        </div>
      </div>
    </div> -->


    <div class="section" id="paper">
      <h2>Citation</h2>
    <pre class="bibtex">
@article{li2024rd,
title={RD-VIO: Robust visual-inertial odometry for mobile augmented reality in dynamic environments},
author={Li, Jinyu and Pan, Xiaokun and Huang, Gan and Zhang, Ziyang and Wang, Nan and Bao, Hujun and Zhang, Guofeng},
journal={IEEE transactions on visualization and computer graphics},
volume={30},
number={10},
pages={6941--6955},
year={2024},
publisher={IEEE}
}
    </pre>
    </div>

    <div class="section">
      <h2>ACKNOWLEDGMENTS</h2>
      <p>
This work was partially supported by NSF of China (No. 61932003).
The authors would like to thank Xinyang Liu for his kind help in
data collection. Thanks to Danpeng Chen, Weijian Xie and Shangjin
Zhai for their kind help in system fine-tuning and evaluation.    </p>
    </div>
  </div>
</body>
</html>

